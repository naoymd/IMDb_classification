# general settings
epoch_num: 20
batch_size: 32
num_workers: 0
fix_length: 200
min_freq: 10
input_size: 300
output_size: 2

# rnn settings
model: model
rnn: GRU_
attention_rnn: False
bidirection: True
num_layers: 1
hidden_size: 512
skip: False
nhead: 4
dropout: 0.5

# attention settings
self_attention: True
qkv_linear: True
mask: False
scaled: True
output_mode: ""

# optimizer settings
learning_rate: 1e-8
min_learning_rate: 1e-12
patience: 0
cooldown: 0
factor: 0.1
weight_decay: 1e-4
clip: 0.5
